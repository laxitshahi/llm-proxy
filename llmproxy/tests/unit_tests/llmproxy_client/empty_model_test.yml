llm_proxy:
  name: LLM proxy API
  version: demo 1.0
  description: An API that act as a proxy to multiple language models

provider_settings:
  - provider: OpenAI
    api_key_var: OPENAI_API_KEY # .env name for api key
    max_output_tokens: 256
    temperature: 0.1
    models: # input names of models you want to you (see below for all models provided)

  - provider: Mistral
    api_key_var: HUGGING_FACE_API_KEY
    max_output_tokens: 256
    temperature: 0.1
    models:
<<<<<<< HEAD
      - name: gpt-3.5-turbo-1106
        cost_per_token_input: 0.0000010
        cost_per_token_output: 0.0000020
      - name: gpt-3.5-turbo-instruct
        cost_per_token_input: 0.0000015
        cost_per_token_output: 0.0000020
      - name: gpt-4
        cost_per_token_input: 0.00003
        cost_per_token_output: 0.00006
      - name: gpt-4-32k
        cost_per_token_input: 0.00006
        cost_per_token_output: 0.00012

  - name: Llama2
    class: llmproxy.provider.huggingface.llama2.Llama2
    models:
      - name: Llama-2-7b-chat-hf
        cost_per_hour: 0.06
      - name: Llama-2-13b-chat-hf
        cost_per_hour: 0.06
      - name: Llama-2-70b-chat-hf
        cost_per_hour: 0.06

  - name: Mistral
    class: llmproxy.provider.huggingface.mistral.Mistral
    models:
      - name: Mistral-7B-v0.1
        cost_per_hour: 0.06
      - name: Mistral-7B-Instruct-v0.1
        cost_per_hour: 0.06
=======
      - Mistral-7B-v0.1
      - Mistral-7B-Instruct-v0.2
      - Mistral-8x7B-Instruct-v0.1
>>>>>>> 2f573f8866c0502f04cf7c5b7c8e2b14dbe2691a
