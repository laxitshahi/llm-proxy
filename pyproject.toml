[tool.poetry]
name = "llm-proxy"
version = "0.1.0"
description = "LLM Proxy to reduce cost and complexity of using multiple LLMs"
authors = ["laxitshahi"]
readme = "README.md"

[tool.poetry.dependencies]
python = "^3.11"
openai = "^0.28.1"
python-dotenv = "^1.0.0"
pytest = "^7.4.2"
pytest-cov = "^4.1.0"
cohere = "^4.27"
tiktoken = "^0.5.1"
tokenizers = "^0.14.1"
transformers = {extras = ["torch"], version = "^4.35.2"}
torch = "^2.1.0"
google-cloud-aiplatform = "^1.35.0"
pyyaml = "^6.0.1"
datasets = "^2.14.7"
evaluate = "^0.4.1"

[tool.poetry.group.dev.dependencies]
black = "^23.9.1"
pytest = "^7.4.2"
coverage = "^7.3.2"
pytest-cov = "^4.1.0"

[tool.pytest.ini_options]
# filterwarnings = ["ignore::DeprecationWarning"]

pythonpath = ["."]

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
